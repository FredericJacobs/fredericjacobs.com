<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BrainOverfl0w</title>
    <description>Frederic Jacobs&#39; Personal Blog</description>
    <link>https://www.fredericjacobs.com/blog/</link>
    <atom:link href="https://www.fredericjacobs.com/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 17 Mar 2016 00:04:36 +0100</pubDate>
    <lastBuildDate>Thu, 17 Mar 2016 00:04:36 +0100</lastBuildDate>
    <generator>Jekyll v3.1.2</generator>
    
      <item>
        <title>My First TEDx Talk</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/meOnStage.jpg&quot; alt=&quot;Me giving a talk at TEDx Brussels&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I gave a TEDx talk in Brussels on the 14th of March on the topic of master keys. Giving a TEDx talk is a very challenging and intimidating experience for anyone who is not an english native speaker since the bar is so high and most speakers have extensive public speaking experience. The video is not yet online, but here’s a transcript. I will update this post to embed the video when it will be online.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Last August, I was getting ready for a trip to the United States. After packing my luggage, I thought it would be useful to have a lock to protect some valuables in my luggage both while traveling and when I was hiking, leaving luggage behind. After a little bit of searching, I found my lock in the closet. It seemed the lock could be unlocked either by entering a digits combination or by opening it with a key. But I couldn’t remember where I left the key.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/lock.jpeg&quot; alt=&quot;My Lock&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Well, it turned out, I didn’t have the key.&lt;/p&gt;

&lt;p&gt;It wasn’t even given to me when I bought the lock.&lt;/p&gt;

&lt;p&gt;After 9/11, the Travel Security Agency was created in the US to “protect the nation’s transportation system”. The TSA made two partnerships to develop locks that they could open to inspect luggage without having to break the locks. They would do this by adding a key slot that could only be opened by the TSA keys. These locks became mandatory when traveling to the United States and any other lock would just have to be destroyed.&lt;/p&gt;

&lt;p&gt;While the measure was of good faith after a horrendous act of terrorism, the results were really disappointing.&lt;/p&gt;

&lt;p&gt;TSA agents cut these locks off despite having the keys in more than 3500 cases in 2011 alone. A report concluded that there was a lot of uncertainty about the efficiency of the measures after observing increased luggage theft of both valuable goods as well as dangerous ones such as guns. Such thefts have raised concerns by national security officials that the same access might allow bombs to be placed aboard aircraft. And things got worse.&lt;/p&gt;

&lt;p&gt;As I was traveling, someone on the Internet figured out that the Washington Post had posted pictures of the locks online, almost a year before.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/TSAKeys.jpeg&quot; alt=&quot;TSA Keys&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From there, a range of events unravelled really quickly. Within 10 days, a group of lock-picking enthusiasts had modeled the keys in high resolution and used 3D printers to reproduce the set of keys. The model can now be downloaded from the code-sharing website &lt;a href=&quot;https://github.com/Xyl2k/TSA-Travel-Sentry-master-keys&quot;&gt;GitHub&lt;/a&gt; and reproduced by anyone with a 3D printer, in minutes.&lt;/p&gt;

&lt;p&gt;Whatever security I could have had from my lock was at that point completely gone. Of course, these locks aren’t very safe to begin with, but now not even lock picking skills are required to unlock them. Anyone can.&lt;/p&gt;

&lt;p&gt;While these locks were meant to make us safer, they turned into a security nightmare. Let me give you another example.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/Yale1620.jpeg&quot; alt=&quot;Yale 1620&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This key, known to firefighters as the Yale 1620,  gives you full access to any elevator in New York City. That means you can lock down any elevator in any skyscraper in NYC. But it also unlocks all the subway emergency exits and entries to any construction site in the city. Firefighters and national security officials have been describing the key as the ultimate terrorism tool if it ends up in the wrong hands.&lt;/p&gt;

&lt;p&gt;Last September, a reporter from the New York Post &lt;a href=&quot;http://nypost.com/2015/09/20/the-8-key-that-can-open-new-york-city-to-terrorists/&quot;&gt;revealed that the key could be acquired online&lt;/a&gt; for $8. I’m really not sure how people of New York City feel about realizing that they could be trapped at the top of a skyscraper or bombs could be placed in the subway tunnels by anyone willing to spend $8 on this key.&lt;/p&gt;

&lt;p&gt;While both of these measures were trying to address very important issues, the way they were implemented ended up considerably weakening the security of these systems in general, instead of making them safer. The fundamental issue is the destruction of diversity which gives natural strength to the system.&lt;/p&gt;

&lt;p&gt;Where previously a bad guy needed 300 million different keys to break into those locks, he now only needs to 3D print this set of keys. The TSA isn’t going to replace all 300 million locks that are unlockable with the keys that are available online. And New York City won’t be able to change hundreds of thousands of elevator locks overnight. While the city of New York is going to try and outlaw the ownership of those keys, about 50 people have already been arrested, thousands more will get a copy distributed as a file. The scale of these weaknesses make it so expensive and time-consuming to replace that about a decade will be needed to move away from those broken locks. And that is, if we get them to care enough.&lt;/p&gt;

&lt;p&gt;In a &lt;a href=&quot;https://theintercept.com/2015/09/17/tsa-doesnt-really-care-luggage-locks-hacked/&quot;&gt;recent piece in the Intercept&lt;/a&gt;, a TSA spokesperson reveals they don’t really care about the locks being compromised, citing them as being “peace of mind” devices, admitting that they never intended them to be safe anyways. Well, that’s reassuring.&lt;/p&gt;

&lt;p&gt;There has to be a solution, there has to. As the quote says:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“For every complex problem there is an answer that is clear, simple,”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and wrong …&lt;/p&gt;

&lt;p&gt;This universal key, sometimes referred as golden key is a perfect example of this. On paper, a master key that would allow the TSA to unlock luggage in the search for bombs sounds completely reasonable, but in practice the key will leak and everybody will end up being less safe.&lt;/p&gt;

&lt;p&gt;I can give you a lot of other examples. I’m not a lock picker, but I do work with locks, digital ones.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/digitalLockpicker.jpeg&quot; alt=&quot;Digital Lockpicker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If I were to ask to anyone in the audience if I could take their  smartphone and post the content of it online, I doubt anyone would take me up on that offer. Whereas your luggage lock may only protect a few valuables, your phone’s passcode protects your thoughts, memories and most personal moments and information. Compromise of phone backups have been ruining careers and lives. Our phones have become an extension of our brains, an extension of the mind. They remind us about what we forget. They illustrate our memories with the pictures we take. They keep our most personal secrets. Realizing that the mental process can occur somewhere else than in the brain is something we need to start accepting as we’re increasingly connected and dependent on technology to make decisions on a daily basis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/BrainPhone.jpeg&quot; alt=&quot;Brain Phone&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Our phones are also our gateway to the Internet. It is often said that the Internet was not designed for the scale it has today since it was primarily designed to meet the needs of the ARPANET network that was connecting labs across the US. But, in the context of the ARPANET, thousands of miles of Internet cables were considered trusted. The Internet was not designed with security in mind. While many of the assumptions were reasonable for the ARPANET, the threat model has changed quite a lot. The Internet has been militarized and bad guys are running all sorts of hacking and sniffing operations on the Internet backbone.&lt;/p&gt;

&lt;p&gt;When email was invented, it was not designed with an adversarial threat model. In the email protocol, it’s trivial to send an email as someone else. Just google it, it will take you 5 minutes, or less.&lt;/p&gt;

&lt;p&gt;Email was not designed to be private either. A few weeks ago, I had to get paperwork filed with the Belgian Embassy. It turns out, that the email server of the diplomatic services worldwide doesn’t accept any mail over an encrypted connection. This means that anyone with network access between my email server and the Belgian Embassy email server can read my mail. This has to be fixed. Think about the consequences of this for a journalist or human rights worker in China or Iran.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/unencryptedMail.jpeg&quot; alt=&quot;Unencrypted mail&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We need to go the full distance. We can design messaging services that work the way users would expect, where messages are only readable by the sender and the receiver, and not by the creepy postman who has been reading your mail.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/e2e.jpeg&quot; alt=&quot;End-to-end&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The security community has been working on making a lot of these tools safer. And we’re getting there.&lt;/p&gt;

&lt;p&gt;The debate about backdoors is often framed in the press as being a debate between privacy and security. This is a false dichotomy. Privacy is the power of being able to selectively disclose your identity to others. You can’t have privacy without security. You can’t have privacy if you can’t technically enforce ownership on your data. Backdoors won’t make us safer either : introducing a master key in the system, as we’ve seen, weakens the security for everyone. Making us more vulnerable to theft and espionage, at scale.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/tedx/power.jpeg&quot; alt=&quot;Call to action&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As companies and nations have been been failing to protect human rights such as privacy, we have been developing tools that protects those rights relying on the laws of nature, rather than the laws of nations. As these tools are making it into the mainstream, there is some push back against these technological advances from regulators and spying agencies who are unhappy about their job becoming harder. Now that the technology is mature, it is our duty to make sure that we can keep on using it to protect our rights.&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;
</description>
        <pubDate>Wed, 16 Mar 2016 23:00:00 +0100</pubDate>
        <link>https://www.fredericjacobs.com/blog/2016/03/16/tedx/</link>
        <guid isPermaLink="true">https://www.fredericjacobs.com/blog/2016/03/16/tedx/</guid>
        
        
      </item>
    
      <item>
        <title>Bumping into Stallman, again</title>
        <description>&lt;p&gt;This is the second time I’m talking at the same conference as Richard Stallman, after the &lt;a href=&quot;https://ind.ie/archive/summit/&quot;&gt;Ind.ie Tech Summit&lt;/a&gt; in Brighton, this time was at the &lt;a href=&quot;https://fri-software-days.ch/index.php?lang=en&quot;&gt;Fri Software Days&lt;/a&gt; in Fribourg, Switzerland.&lt;/p&gt;

&lt;p&gt;One day before my presentation, I got an email from the organizers, letting me know that Stallman would like me to rename the title of my talk to remove any mentions of “Open Source Software” and replace them with “Free Software”.&lt;/p&gt;

&lt;p&gt;The email read like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Is it feasible to remove the terms “Open-Source” from the title of your presentation and replace them by “Free-libre software”? It’s the wish of M. Stallman, that will probably attend your talk.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Apparently, Stallman has been doing this for some time now, &lt;a href=&quot;http://pastebin.com/ADSHJrHm&quot;&gt;as this email from 2011 shows&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;So please make sure that all the publicity about the event (web site, email announcements, conference programs, direct mail, signs, etc), uses the term “free software”, not “open source”, when you refer to work that includes mine.  This includes to the title and descriptions of my speech, of the session it is in, of the track it is part of, and of the event itself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I told the organizers, that I would stand by my use of OSS because that’s what was the right term to use in the context of my presentation on “(Open Source) Software Supply Chain Security”. My talk was about any kind of software that has accessible source code and referring to “Free Software” would have been restrictive of what I really wanted to talk about. Just to make it clear, despite Stallman’s wishes, no modifications to my title or abstract were made.&lt;/p&gt;

&lt;p&gt;Freedom starts with being able to choose the words I use to describe my own talk, if you ask me.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/img/Stallman.JPG&quot; alt=&quot;Stallman evangelizes Fri Software Days about Free Software&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Stallman narrative of blaming the users for choosing to use “what just works” and looks great over “Free Software” is counter-productive. Until you build beautiful and viable alternatives, you can’t keep on blaming the users. And standing in denial isn’t helping. In his call for action, he encouraged programmers and activists to join the movement but he systematically leaves out the people the “Free Software” community desperately needs the most, UX and UI designers.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;During the Q&amp;amp;A, someone from the audience asked how someone could live from writing “Free software”. Stallman referred to himself as the perfect example that it was possible.    He finished answering that question with the following widely inappropriate comment:&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&amp;quot;Ian Murdoch did kill himself, but he was more of an open source supporter. Free software didn&amp;#39;t kill anyone.&amp;quot; ~Stallman going too far ...&lt;/p&gt;&amp;mdash; Frederic Jacobs (@FredericJacobs) &lt;a href=&quot;https://twitter.com/FredericJacobs/status/694235802100961281&quot;&gt;February 1, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;Stallman is going too far, his religious war of “Free Software” against the evil “Open Source” is out-of-sync with reality, and has become quite embarrassing for anyone using GPL licenses and defend a different vision of the Free Software movement.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Update 1&lt;/strong&gt; (2015-02-03 15:00 GMT): Adding slides of the talk on OSS Supply Chain Security&lt;/p&gt;

&lt;script async=&quot;&quot; class=&quot;speakerdeck-embed&quot; data-id=&quot;25823f7b79014e63955509834f1a4c80&quot; data-ratio=&quot;1.33333333333333&quot; src=&quot;//speakerdeck.com/assets/embed.js&quot;&gt;&lt;/script&gt;

</description>
        <pubDate>Tue, 02 Feb 2016 23:25:00 +0100</pubDate>
        <link>https://www.fredericjacobs.com/blog/2016/02/02/stallmanism/</link>
        <guid isPermaLink="true">https://www.fredericjacobs.com/blog/2016/02/02/stallmanism/</guid>
        
        
      </item>
    
      <item>
        <title>Revisiting the NSA Suite B Announcement</title>
        <description>&lt;p&gt;In August 2015 the NSA &lt;a href=&quot;https://www.nsa.gov/ia/programs/suiteb_cryptography/index.shtml&quot;&gt;released a major policy statement&lt;/a&gt; on the need for post-quantum cryptography, updating its Suite B recommendations in the process.&lt;/p&gt;

&lt;p&gt;The announcement surprised most of the crypto community with inconsistencies in the recommendations and interrogations about whether or not the threat posed by quantum computers was overblown.&lt;/p&gt;

&lt;p&gt;In their &lt;a href=&quot;https://eprint.iacr.org/2015/1018&quot;&gt;“A Riddle Wrapped in an Enigma”&lt;/a&gt; paper, N. Koblitz &amp;amp; Alfred Menezes speculated about NSA freaking out about the adoption of ECC. Matthew Green &lt;a href=&quot;http://blog.cryptographyengineering.com/2015/10/a-riddle-wrapped-in-curve.html&quot;&gt;also critically blogged about the paper.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Earlier this month, the IAD quietly &lt;a href=&quot;https://www.iad.gov/iad/library/ia-guidance/ia-solutions-for-classified/algorithm-guidance/cnsa-suite-and-quantum-computing-faq.cfm&quot;&gt;posted a FAQ&lt;/a&gt; document providing some more details about the changes in the recommendations. Here are some highlights.&lt;/p&gt;

&lt;h2 id=&quot;compliance&quot;&gt;Compliance&lt;/h2&gt;

&lt;p&gt;In the &lt;a href=&quot;https://www.fredericjacobs.com/blog/2015/12/18/COMSEC/&quot;&gt;NSA COMSEC Guide&lt;/a&gt; it was revealed that NSA was highly interested in collaborating with the industry so that industry could provide more “integrated” encryption solutions and NSA wouldn’t have to layer crypto on top of commercial products. Therefore, the FAQ document is mostly targeted for these “NSS” (national security systems) vendors.&lt;/p&gt;

&lt;h2 id=&quot;timing&quot;&gt;Timing&lt;/h2&gt;

&lt;p&gt;The FAQ claims that the timing of the Suite B updates was an opportune moment to make the announcement about Quantum resistance but no particular breakthrough motivated the update of the recommendations.&lt;/p&gt;

&lt;h2 id=&quot;primitives&quot;&gt;Primitives&lt;/h2&gt;

&lt;p&gt;The current Suite B recommendations are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;RSA 3072-bit or larger&lt;/li&gt;
  &lt;li&gt;DH 3072-bit or larger&lt;/li&gt;
  &lt;li&gt;ECDH and ECDSA with NIST P-384&lt;/li&gt;
  &lt;li&gt;SHA-384&lt;/li&gt;
  &lt;li&gt;AES-256&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;with the note:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NSA prefers the use of ECDH with P-384 and 3072-bit DH for key establishment.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And the document explicitly says the following primitives should no longer be used for NSS:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ECDH and ECDSA with NIST P-256&lt;/li&gt;
  &lt;li&gt;SHA-256&lt;/li&gt;
  &lt;li&gt;AES-128&lt;/li&gt;
  &lt;li&gt;RSA with 2048-bit keys&lt;/li&gt;
  &lt;li&gt;DH with 2048-bit keys&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;threat-of-quantum-computing&quot;&gt;Threat of Quantum Computing&lt;/h2&gt;

&lt;p&gt;The document says that it takes up to 20 years for algorithms to be fully deployed on NSS, and the equipment is often used for 30 years or more. NSA refers to “many experts” that predict a quantum computer capable of effectively breaking public key crypto within that timeframe and that it is important to address that concern.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Choosing the right time to champion the development of quantum resistant standards is based on 3 points: forecasts on the future development of a large quantum computer, maturity of quantum resistant algorithms, and an analysis of costs and benefits to NSS owners and stakeholders. NSA believes the time is now right—consistent advances in quantum computing are being made, there are many more proposals for potentially useful quantum resistant algorithms than were available 5 years ago, and the mandatory change to elliptic curves that would have been required in October 2015 presented an opportune time to make an announcement. NSA published the advisory memorandum to move to quantum resistant symmetric key options and to allow additional continued use of older public key options as a way to reduce modernization costs in the near term. In the longer term, NSA is looking to all NSS vendors and operators to implement standards-based, quantum resistant cryptography to protect their data and communications.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;nsa-on-nist&quot;&gt;NSA on NIST&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;NSA will continue to support NIST in the standardization process and will also encourage work in the vendor and larger standards communities to help produce standards with broad support for deployment in NSS. NSA believes that NIST can lead a robust and transparent process for the standardization of publicly developed and vetted algorithms, and we encourage this process to begin soon. NSA believes that the external cryptographic community can develop quantum resistant algorithms and reach broad agreement for standardization within a few years.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;does-the-fact-nsa-is-making-this-change-today-mean-a-quantum-computer-exists&quot;&gt;Does the fact NSA is making this change today mean a quantum computer exists?&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;NSA does not know if or when a quantum computer of sufficient size to exploit public key cryptography will exist. The cryptographic systems that NSA produces, certifies, and supports often have very long life-cycles. NSA has to produce requirements today for systems that will be used for many decades in the future, and data protected by these systems will still require cryptographic protection for decades after these solutions are replaced. There is growing research in the area of quantum computing, and enough progress is being made that NSA must act now to protect NSS by encouraging the development and adoption of quantum resistant algorithms.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;qkd&quot;&gt;QKD&lt;/h2&gt;

&lt;p&gt;NSA briefly mentions QKD as a possible solution. I haven’t seen any QKD scheme myself that has the desired no-MITM property that it claims it has. Most schemes make the unreasonable assumption that there exists a public classic channel between Alice and Bob and that Eve would only mess with the qubits. This assumes that the classical channel is already authenticated so it doesn’t really solve the post-quantum crypto problem since they already have a secure communication channel (symmetric crypto is not believed to be vulnerable to QC if key sizes make a Grover search unfeasible).&lt;/p&gt;

&lt;p&gt;NSA says they have no plans to use quantum cryptography, it wouldn’t be realistic to do so.&lt;/p&gt;

&lt;h2 id=&quot;on-the-rsadh-recommendation&quot;&gt;On the RSA/DH recommendation&lt;/h2&gt;

&lt;p&gt;NSA wants to keep supporting these “legacy” algorithms because of cost effectiveness, suggesting that asking those vendors to move to ECC, only to move to a post-quantum algorithm in a few years would be a waste of effort.&lt;/p&gt;

&lt;p&gt;NSA makes it clear that they still encourage vendors to move to ECC, but if the vendors can’t comply to the new advisory within a limited timeframe, they can just transition to the quantum resistant cryptography, whenever that comes.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The document brings light to some of the questions the crypto community had been wondering about since the announcement. Not all recommendations are equal. Nuancing that some algorithms (DH &amp;amp; RSA) are now being transitioned towards “legacy” status but are still in the recommendation for giving vendors more time to transition is an important clarification.&lt;/p&gt;

&lt;p&gt;I believe ECC isn’t going away anytime soon, especially for systems at scale. Some HTTPS reverse-proxies serve millions of users and the move to quantum resistant crypto would make that impractical due to increased key sizes. Therefore, suggesting that vendors can just bump RSA key size waiting for a post-quantum standard sounds unwise.&lt;/p&gt;

&lt;p&gt;It’s exciting to see more people looking at NTRU or McEliece and working on better implementations than the naive academic ones but there is still a long way to go before large scale deployments.&lt;/p&gt;

&lt;p&gt;Probably see you on a NIST, CFRG or PQCrypto mailing list to discuss this further!&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Jan 2016 21:00:00 +0100</pubDate>
        <link>https://www.fredericjacobs.com/blog/2016/01/27/NSA-QC/</link>
        <guid isPermaLink="true">https://www.fredericjacobs.com/blog/2016/01/27/NSA-QC/</guid>
        
        
      </item>
    
      <item>
        <title>On SMS logins: an example from Telegram in Iran</title>
        <description>&lt;p&gt;Most mobile messaging apps these days use SMS as a login technique. It’s really convenient because it doesn’t require the user to remember yet another username or identifier and telcos are taking care of the identity management such as re-assigning the phone number to you if you lose your phone.&lt;/p&gt;

&lt;p&gt;SMS are trivial to intercept for your telecom provider. And in almost all countries, they are actively cooperating with the state to help intercept text messages and phone calls. But it’s not only your telecom provider, devices like IMSI catchers provide a cheap and efficient way of intercepting text messages for a local adversary.&lt;/p&gt;

&lt;p&gt;Applications such as Telegram messenger, not only allows a user to signup with an SMS, but also enables them to log in to see previous messages. The application stores your messages, content and contacts as they disclose in their &lt;a href=&quot;https://telegram.org/privacy&quot;&gt;privacy policy&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We store messages, photos, videos and documents from your cloud chats on our servers, so that you can access your data from any of your devices anytime and use our instant server search to quickly access your messages from waaay back.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;An attacker, that can intercept a single SMS is therefore capable of reading your messages from “waaay back”.&lt;/p&gt;

&lt;p&gt;Attacks like that are not just theoretical. Let’s take a recent example, Iran.&lt;/p&gt;

&lt;p&gt;Telegram has gotten a huge amount of signups in Iran and &lt;a href=&quot;https://twitter.com/durov/status/687254676157378560&quot;&gt;according to Durov&lt;/a&gt;, its founder, Iranian users constitute up to 20% of their user base.&lt;/p&gt;

&lt;p&gt;When Telegram was getting some traction over the summer (June 2015), Iranian users started getting unsolicited login messages to sign into the Telegram website, which were believed to be related to a Telegram interception program operated by Iranian intelligence. Check the replies to this tweet:&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;fa&quot; dir=&quot;rtl&quot;&gt;کیا این پیام رو امروز از &lt;a href=&quot;https://twitter.com/hashtag/%D8%AA%D9%84%DA%AF%D8%B1%D8%A7%D9%85?src=hash&quot;&gt;#تلگرام&lt;/a&gt; گرفتند؟&amp;#10;&lt;a href=&quot;https://twitter.com/hashtag/%D8%B1%DB%8C%D8%AA%D9%88%DB%8C%DB%8C%D8%AA?src=hash&quot;&gt;#ریتوییت&lt;/a&gt;&amp;#10;&amp;#10;&lt;a href=&quot;https://twitter.com/hashtag/%D8%A7%D8%B3%D9%BE%D9%85?src=hash&quot;&gt;#اسپم&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/%D8%A7%D9%85%D9%86%DB%8C%D8%AA?src=hash&quot;&gt;#امنیت&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/Iran?src=hash&quot;&gt;#Iran&lt;/a&gt; &lt;a href=&quot;http://t.co/xxEJBZbWSf&quot;&gt;pic.twitter.com/xxEJBZbWSf&lt;/a&gt;&lt;/p&gt;&amp;mdash; Nariman (@NarimanGharib) &lt;a href=&quot;https://twitter.com/NarimanGharib/status/612310940453892096&quot;&gt;June 20, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;Over the past few months, there has been a lot of chatter about the relationship between Telegram and Iran. It is widely known that Iran blocks services that blinds their intelligence branches and that are unwilling to cooperate. Durov repeatedly came out claiming that they were not collaborating with Iran outside of blocking porn and jihadi channels (for public content), which they are doing worldwide.&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/persianbanoo&quot;&gt;@persianbanoo&lt;/a&gt; &lt;a href=&quot;https://twitter.com/SinaKK&quot;&gt;@SinaKK&lt;/a&gt; We shut down porn / ISIS channels based on the reports from users. &lt;a href=&quot;https://twitter.com/telegram&quot;&gt;@telegram&lt;/a&gt; never does political censorship.&lt;/p&gt;&amp;mdash; Pavel Durov (@durov) &lt;a href=&quot;https://twitter.com/durov/status/687315543448285184&quot;&gt;January 13, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;More recently, some popular Telegram channels promoting political poems or ideologies have been shut down. Iranian activists asked Durov about why those political channels were suspended.&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Mr &lt;a href=&quot;https://twitter.com/durov&quot;&gt;@durov&lt;/a&gt; can you explain why you closed the PDKI channel in &lt;a href=&quot;https://twitter.com/telegram&quot;&gt;@telegram&lt;/a&gt;? :)&amp;#10;&lt;a href=&quot;https://twitter.com/hashtag/Censorship?src=hash&quot;&gt;#Censorship&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/Telegram?src=hash&quot;&gt;#Telegram&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/PDKI?src=hash&quot;&gt;#PDKI&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/Iran?src=hash&quot;&gt;#Iran&lt;/a&gt; &lt;a href=&quot;https://t.co/wvUrCes7fT&quot;&gt;pic.twitter.com/wvUrCes7fT&lt;/a&gt;&lt;/p&gt;&amp;mdash; Kevin Miston (@KevinMiston) &lt;a href=&quot;https://twitter.com/KevinMiston/status/686537567051890688&quot;&gt;January 11, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;fa&quot; dir=&quot;rtl&quot;&gt;یک روز از خواب پا میشی، می بینی رفتی به...&amp;#10;کانال تلگرامم حذف شد/ کردند؟! &lt;a href=&quot;https://t.co/C5KMj99jhg&quot;&gt;pic.twitter.com/C5KMj99jhg&lt;/a&gt;&lt;/p&gt;&amp;mdash; فاطمه اختصاری (@fatemeekhtesari) &lt;a href=&quot;https://twitter.com/fatemeekhtesari/status/686847201797103616&quot;&gt;January 12, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;After investigation, Telegram said that the channels were not suspended, but deleted by their owners.&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/KevinMiston&quot;&gt;@KevinMiston&lt;/a&gt; &lt;a href=&quot;https://twitter.com/durov&quot;&gt;@durov&lt;/a&gt; Investigation showed: The owner deleted his account on Jan 10, so all his channels became unavailable. Nothing blocked.&lt;/p&gt;&amp;mdash; Telegram Messenger (@telegram) &lt;a href=&quot;https://twitter.com/telegram/status/686656336059318273&quot;&gt;January 11, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;These are probably just a few examples of hacked channels. &lt;em&gt;Unlike surveillance, censorship can be observed.&lt;/em&gt; It’s only because Iran started deleting popular channels that it became clear that they were hacking into Telegram accounts but how many activists got arrested over Telegram discussions that were intercepted? That is significantly more difficult to evaluate.&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Further investigation of some of the cases:IRI hacking into accounts,not censorship.Tnx &lt;a href=&quot;https://twitter.com/telegram&quot;&gt;@telegram&lt;/a&gt; 4 being responsive&amp;#10;&lt;a href=&quot;https://t.co/QGk7picBcF&quot;&gt;https://t.co/QGk7picBcF&lt;/a&gt;&lt;/p&gt;&amp;mdash; Reza Ghazinouri (@ghazinouri) &lt;a href=&quot;https://twitter.com/ghazinouri/status/687399529918894080&quot;&gt;January 13, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;Despite good intentions, it’s becoming clearer that a good number of activists who trusted the application that branded itself as the “safest” messaging app are getting their account hacked and channels deleted.&lt;/p&gt;

&lt;p&gt;Countries like Iran tend to be blocking applications that blinds their intelligence as they get popular. Repeated claims by the authorities that they wouldn’t block Telegram should already have sounded suspicious. &lt;strong&gt;If a single SMS enables you to get access to a user’s account and data, you designed your system with a backdoor that any serious adversary can exploit.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;does-this-affect-only-telegram&quot;&gt;Does this affect only Telegram?&lt;/h2&gt;

&lt;p&gt;No, other services where you only need to send an SMS to log in are affected by this. But unlike Telegram, a lot of other messaging applications don’t store your messages and content server-side.&lt;/p&gt;

&lt;p&gt;This is a reminder for all users of messaging apps in risky environment, &lt;strong&gt;verify fingerprints&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;SMS activation in most messaging apps can be compared to your server sign in for Jabber when using OTR. It is just your login to the message server, unless you verify fingerprints, you are still at risk of interception.&lt;/p&gt;

&lt;h2 id=&quot;mitigations&quot;&gt;Mitigations:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://telegram.org/blog/sessions-and-2-step-verification&quot;&gt;Enable 2-Step authentication (and verify active sessions while you’re at it)&lt;/a&gt; and only use “secret chats”.&lt;/li&gt;
  &lt;li&gt;Or just move to an application that won’t store plaintext messages on their servers if you’re operating in such a risky environment.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;note-on-two-factor-authentication&quot;&gt;Note on two-factor authentication&lt;/h2&gt;

&lt;p&gt;Because of the weaknesses of the SMS protocol, it’s generally safer to setup two-factor authentication with a YubiKey or TOTP (such as Google Authenticator). Unfortunately, many services don’t let you opt-out of SMS fallback for second factor authentication.&lt;/p&gt;

&lt;p&gt;Disclosure: I have previously worked on encrypted messaging software.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Update I:&lt;/strong&gt; Telegram clarified that one of the mentioned channels was deleted because of inactivity.&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/CDA&quot;&gt;@CDA&lt;/a&gt; &lt;a href=&quot;https://twitter.com/Ammir&quot;&gt;@Ammir&lt;/a&gt; &lt;a href=&quot;https://twitter.com/KevinMiston&quot;&gt;@KevinMiston&lt;/a&gt; This channel got deleted because it was created by an inactive account that was set to self-destruct by its owner.&lt;/p&gt;&amp;mdash; Pavel Durov (@durov) &lt;a href=&quot;https://twitter.com/durov/status/687632744252354561&quot;&gt;January 14, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;It is also important to note that some other accounts could also have been compromised by malware since some samples are looking for activation SMSes.&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jan 2016 14:00:00 +0100</pubDate>
        <link>https://www.fredericjacobs.com/blog/2016/01/14/sms-login/</link>
        <guid isPermaLink="true">https://www.fredericjacobs.com/blog/2016/01/14/sms-login/</guid>
        
        
      </item>
    
      <item>
        <title>Some bits from the NSA COMSEC Guide</title>
        <description>&lt;p&gt;A few weeks ago, &lt;a href=&quot;http://www.governmentattic.org/18docs/Hist_US_COMSEC_Boak_NSA_1973u.pdf&quot;&gt;additional parts&lt;/a&gt; of the “A History of U.S. Communications Security” books from the NSA were declassified. A little intrigued, I decided to read the second volume that was originally published in 1981 under the &lt;a href=&quot;https://en.wikipedia.org/wiki/Classified_information#Secret&quot;&gt;SECRET&lt;/a&gt; classification. I wondered what we could learn, in 2015, from the dated document.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: For legibility reasons I transcripted the original notes. Italic was in original text. I’m highlighted segments in bold and added links for important references.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-comsecopsec&quot;&gt;Why COMSEC/OPSEC?&lt;/h2&gt;

&lt;p&gt;The main argument for COMSEC for military operations that the author is bringing forward is that COMSEC is a crucial element to maintain the “surprise” element of operations.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Operations Security (OPSEC) is a discipline designed fundamentally to attain and maintain surprise, particularly in military operations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;COMSEC is a key ingredient of OPSEC - it may help achieve surprise, nor with the correlative assertion that fewer and fewer major operations can be planned and executed these days without a large amount of supporting communications to coordinate, command and control them, nor even with the assertion that,without security for those communications, surprise is unlikely&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;on-threat-modeling&quot;&gt;On Threat Modeling&lt;/h2&gt;

&lt;p&gt;No COMSEC tool (messaging app, radio,  … ) is a silver bullet. Ideally, it will minimize “what could go wrong”, but there will always be ways of using it in an unsafe manner. Authentication  is one of the hardest challenges that is yet to solve. Asking people to manually verify fingerprints comes at a huge usability trade-off. The following segment highlights the important idea of first trying to find technical solutions to the problem before going after procedural solutions. Nobody likes manual key verification, but no technical solution has currently been found to satisfy the same level of security without adding that procedural step.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In olden times, most of our programs, whether in equipment development, TEMPEST, or security procedures were driven largely by our view of COMSEC weaknesses - our vulnerabilities - more or less independent of judgements made on the ability of an opponent to exploit them. We assumed hostile SIGINT to be at least as good as ours, and used that as a baseline on what might happen to us. If we perceived a weakness, we would first try for a technical solution - like new crypto-equipment. If the state of the art did not permit such a solution, or could do so only at horrendous expense, we’d look for procedural solutions and, those failing, would leave the problem alone.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;So our priorities were developed more or less in the abstract, in the sense that they related more to what we were able to do technologically or procedurally than the probabilities that a given weakness would be exploited in a given operating environment. In short, we did not do much differentiation between vulnerabilities which were usually fairly easy to discover and threats (which were more difficult to prove) - where threats are are fairly rigorously defined to mean demonstrated hostile capabilities, intentions, and/or successes against U.S. communications. The accusations of overkill touched on earlier in part stemmed from that approach.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The thrust towards gearing our countermeasures to threat rather than theoretical vulnerability was healthy, and driven by a recognition that our resources were both finite and, for the foreseeable future, inadequate to fix everything. In fact, one of the reactions of an outside analyst to our earlier approach was, &lt;em&gt;“These nuts want to secure the world”&lt;/em&gt;. Some still think so.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;if-your-crypto-doesnt-work-nobody-will-use-it&quot;&gt;If your crypto doesn’t work, nobody will use it&lt;/h2&gt;

&lt;p&gt;During the Vietnam war, the encryption was reducing the transmission range and introducing unacceptable delays in radio communications. Some pilots got frustrated about it and fell back to plaintext communications. A commander had to threaten his pilots to ground them to get them to use NESTOR, the encryption system that was implemented on top of radio communications.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Finally, our own engineers sent to Vietnam reported back: “Sorry about that, S2; the system reduces range - typically by 10% or more.” And it, in fact, did. It turned out that NESTOR did not affect range only if the associated radio was perfectly tuned, “peaked,” matched to the NESTOR equipment (as we naturally did here at home). In the field, maintenance personnel were neither trained nor equipped for such refinement - the test instrumentation simply did not exist there, and we had not anticipated those real world conditions when we sent it out.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;In tactical air, it was claimed that the delay - up to 3/5 of a second of required wait between pushing to talk and ability to communicate - was intolerable when air-to-air warnings among pilots had to be instantaneous. A survey showed, by the away, that most pilots judged this time to be on the order of three seconds; so, in fact, the wait must have seemed interminable when one wanted to say “Bandit at two o’clock.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Most US SIGINT assets in Vietnam used NESTOR heavily and successfully almost from the outset. Towards the end of the war, so did most in-country Naval forces, particularly airborne assets. In the SIGINT user’s case, it was because they were already equipped when they got in country; had used it previously, knew, accepted or circumvented its peculiarities, and, of course, because they believed their traffic required protection. In the Navy case, it was the result of Draconian measures by the Commander, Naval Forces, Vietnam (COMNAVFORV). That Admiral happened to be a COMSEC believer; so he told his pilots that if they didn’t use the equipment, he’d ground them. Some didn’t and he did. There is, I understand, no comparable trauma for a fighter pilot.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;dealing-with-compromise&quot;&gt;Dealing with compromise&lt;/h2&gt;

&lt;p&gt;Every time I read a headline that reads “X is broken” where X is a messaging app, an anonymity program or other, I fear that people might just give up on using encryption thinking that everything is broken anyways and thus it’s useless to take any defensive measures.&lt;/p&gt;

&lt;p&gt;Unless there is a good alternative, it’s really deceptive to just blame the tool that offers the best protection.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A caveat: While nothing gets a user’s attention like documented proof that communications he thinks are sensitive are being read by an opponent, several things should be borne in mind before telling him about it. Foremost is the fragility of the source of the information (the “proof”) you have. Secondly, it is worse than useless to go out and impress a user with a problem unless you have a realistic solution in hand. No matter how dramatic the evidence of threat, if we simply go out and say, “Stop using your black telephone”, it’s likely to be effective for about two weeks. Don’t jeopardize a good source for that kind of payoff.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Finally, the results of our own monitoring and analysis of communications,at best, prove vulnerability, not threat, are often remarkably ineffective. Nothing brought this home more persuasively than the Vietnam experience. Monitoring elements of all four Services demonstrated the vulnerability of tactical voice communications again and again. This did not show that the NVA or VC could do it. It was first argued that they weren’t engaged in COMINT at all. Next, that even if they were able to intercept us, they couldn’t understand us, especially given our arcane tactical communications jargon. Third, even given interception and comprehension, they could not react in time to use the information.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;It took years to dispel those notions with series of proofs in the form of captured documents, results of prisoner and defector interrogations, some US COMINT and, finally, the capture of an entire enemy COMINT unit: radios, intercept operators, linguists, political cadre and all. Their captured logs showed transcriptions of thousands of US tactical voice communications with evidence that their operators were able to break our troops’ home-made point-of-origin, thrust line, and shackle codes in real time. The interrogations confirmed their use of tip-off networks (by wire line or courier) to warn their commanders of what we were about to do - where, when, and with what force.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;de-classification&quot;&gt;De-classification&lt;/h2&gt;

&lt;p&gt;NSA thought that declassifying crypto algorithms would lead to having more integrated options for communication devices. Sadly, a lot of privacy tools are still a hack on top of a protocol (SMS, Jabber, Email …) and not well integrated. As long as crypto is the topmost layer of the &lt;a href=&quot;https://en.wikipedia.org/wiki/OSI_model&quot;&gt;OSI model&lt;/a&gt;, we’re going to lose users.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The two major reasons for declassification were the “inhibition of use” argument, and the vision of full integration of COMSEC circuitry into radios of the future - full integration being defined as inseparable and shared radio and crypto-circuitry. In that configuration, our COMSEC tail would be wagging the communications system dog with the controls classification denotes - how would such equipments be shipped, stored, and particularly, how would they be maintained? “Integration” has thus far not turned out to be the wave of the future. COMSEC modules will by and large be separable from their associated radios because the designers found it more efficient to do it that way. […]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;offence-is-easy&quot;&gt;Offence is easy&lt;/h2&gt;

&lt;p&gt;As the rest of the security community, NSA is good at offence, but has no clue how to secure a system.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It seems to me that &lt;strong&gt;NSA does not yet have much expertise in computer security. Rather, we are expert in computer insecurity.&lt;/strong&gt; We do much better in finding security vulnerabilities in any computer complex than in proposing security architecture for them. Somehow the attack seems more challenging (fun) than the defence, and this seems true in the general business of crypto system design as well. A spin-off of this syndrome manifests itself when a security modification is needed for an existing crypto-equipment. In my experience, most design engineers would &lt;em&gt;much&lt;/em&gt; rather attack a brand new problem - meet a new and difficult requirement - starting from scratch, pushing the electronic state of the art, exercising opportunities for innovations, and so on than go through the drudgery of a mere “fix” accepting the constraints of configuration and technology in some pre-existing piece of hardware.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-cost-of-transparency&quot;&gt;The Cost of Transparency&lt;/h2&gt;

&lt;p&gt;Soviet’s were apparently not revealing any information about their COMSEC programs. I’m not sure we would know much about NSA’s without whistleblowers.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;NSA spends tens of millions of dollars and tens of thousands of man-hours trying to discover what Soviet COMSEC is like. Despite all-source research dating back to more than 30 years, the incidence of any unclassified statements by the Soviets on any aspect of their COMSEC program is so trivial as to be virtually non-existent. In other words, the Soviets protect (classify) all information about their cryptography and associated communications security measures.
The effect of this stone wall has been either to greatly delay U.S. ability to exploit some Soviet communications or frustrate it altogether.
Viewed as an element of economic warfare, we are losing hands down as we expend enormous resources to acquire the same kind of information from the Soviets that we give them free - i.e., without classification.
Clearly, the Soviet’s classification program costs them something, just as ours costs us. But, they have a cost advantage because they still operate in an essentially closed society with a well-established security infrastructure and with many of their officials already well attuned psychologically to the concept of secrecy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;value-of-crypto-analytic-information&quot;&gt;Value of crypto-analytic information&lt;/h2&gt;

&lt;p&gt;For NSA, the best way for breaking a crypto system is to break the math, not the implementation. I assume this argument is based on the fact that a passive attack is superior to an active one.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The optimum attack on any crypto system (if you can hack it) is cryptanalytic - you need only operate on cipher text; your risk is low or non-existent unless you have to position yourself dangerously to perform the interception. You don’t need to steal keys or penetrate cryptocenters or subvert people and, if you succeed, the return on investment is likely to be rich - all the secrets committed to the cryptosystem in question. The one essential pre-requisite to such attack is knowledge of the cryptologic - which may have been the reason why the Soviets were (reportedly) willing to offer $50, 000 for PARKHILL several years ago.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The “SIGINT” argument for protecting our cryptologics is well known - the COMSEC arguments much less so, despite their reiteration for some decades:
	- With the exception of true one-time systems, none of our logics is theoretically and provably immune to cryptanalysis - the “approved” ones have simply been shown to adequately resist whatever kinds of crypto-mathematical attacks we, with our finite resources and brains, have been able to think up. We are by no means certain that the Soviet equivalent of A Group can do no better. But no attack is likely to be successful - and certainly cannot be optimised - without preliminary diagnostics - discovery of how it works.
	- Systems which have no known cryptanalytic vulnerabilities may still be exploited if, and usually only if, their keying materials have been acquired by the opposition or if their TEMPEST characteristics permit it. In either of these contingencies, however, the logic, the machine itself, or both may be required for exploitation to be successful.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Because the thrust for unclassified when unkeyed equipments is lying fallow at the moment, all of the above may seem like beating a dead horse as far as our mainline equipment are concerned. But the matter will assuredly rise again.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;public-cryptography&quot;&gt;Public Cryptography&lt;/h2&gt;

&lt;p&gt;The COMSEC guide also talks about the rise of non-governmental encryption and more specifically the discovery of “RSA” by GCHQ a few years before it was publicly discovered.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;While commercial equipment has been around for many decades, their quantity and variety was relatively small. Most were manufactured overseas - particularly in Switzerland, and no huge market existed for them after World War II because many Governments (like our own) began increasingly to use systems exclusively of their own design and under their own control. Similarly, the amount of published literature on cryptography, and particularly on sophisticated cryptanalytic ideas was sparse. In the U.S., the Government (specifically, NSA) enjoyed a near-monopoly on the subject by the early ’50’s. That persisted until about 1970, when a dramatic change occurred.
A handful of U.S. companies interested in computers, in communications, or in electronics began to perceive a market for electronic crypto-equipments. A few other American companies began building crypto-equipment in competition with the Swiss and others in Europe, supplying devices to some Governments in Africa, South America, and the Middle East and to a few major corporations - notably some oil companies seeking to protect vital industrial secrets.
At about the same time, the question of computer security, which had been on the back burner since the late 50’s, began to get a great deal of attention from computer manufacturers themselves and from some of their customers. Computer fraud had become more common, and its impact, particularly on the banking world, became significant.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;One of the interesting outgrowths of the burgeoning interest in cryptography in the private sector was the “invention” of a concept  called “Public Key Cryptography” (PKC). All conventional cryptography requires the pre-positioning of shared keys with each communicant. The logistics for the manufacturing and delivery of those keys keeps S3 in business and forces uses to maintain a large secure crypto-distribution system. (Remote keying eases but does not eliminate the problem) The thought was, cryptography would be revolutionized if a system could be devised in which people could communicate securely without prior exchange of keys.
The main idea that came forward was an effort to capitalize on the fact that some mathematical functions are easy to carry out in one “direction,” but difficult or impossible to reverse. A classic example of these so-called one-way functions is the phenomenon that it is not hard to multiply two very large prime numbers together, but given only their product, no elegant way has been put forward for determining what the two original numbers were.
So the original numbers could be considered to be part of the one man’s secret “key:” their product could be published; an encryption algorithm could be specified operating on that product which could not be efficiently decrypted without knowledge of the “key”; and all messages addressed to that person would be encrypted by that algorithm.
By coincidence, &lt;strong&gt;the identical idea had been put forward by one of our British colleagues five years earlier, and we and they had been studying it ever since. We called it non-encrypted encryption (NSE) and were trying to solve the same problem of key distribution. We treated our work on it as SECRET and still do. We did not leap to its adoption for a variety of a reason. Foremost, we were uncertain of its security potential.&lt;/strong&gt; The fact that mathematicians had not yet found a way to factor large numbers did not mean that there was no way.
It was an interesting mathematical puzzle, first put forward centuries ago, but no great incentives for its solution beyond the satisfaction of intellectual curiosity, no perceived commercial applications, and so on. So there was no e evidence of a great many brains having worked on the problem over the year; nor did we go all out against it because, apart from theoretical doubts, there were other drawbacks.
The most obvious - although perhaps not the most important - was the fact that the encrypted himself could never decrypt his own message - he would be using the crypto system of the recipient who was the only one holding the secret decrypting key - he would have no means to verify its accuracy or correct an error. More or less elaborate protocols involve hand-shaking between the communications were put forward to get around this difficulty - usually entailing the receiver having to re-encrypt the received message in the sender’s key and asking if it was right. A clumsy business.
Next, each user would have to keep his primes absolutely secret, forcing on each some of the secure storage and control problems inherent within conventional schemes. Known (or unknown) loss would compromise all of his previously received messages. To get around that, relatively frequent change would be necessary. This would move him towards the conventions of keying material supersession; generation and selection of suitable primes and their products, and their republication to all potential correspondents.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;embassies-and-sigint&quot;&gt;Embassies and SIGINT&lt;/h2&gt;

&lt;p&gt;Soviets were suspected of intercepting communications in the Washington area and elsewhere in the United States. Therefore, the NSA was pressured by the Government to disclose and share more about their knowledge about cryptography.&lt;/p&gt;

&lt;p&gt;Soviet SIGINT got out of control and weakened telecom infrastructure was so vulnerable that the Vice-President Rockefeller said: “If you don’t want it known, don’t use the phone”. Take that as an opsec advice.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Another major factor arose bringing great pressure on NSA to let some of our cats out of the bag. This was the matter of Soviet interception of communications in the Washington area and elsewhere in the United States. By 1966, we were pretty sure that they were doing this work from their Embassy on 16th Street and perhaps from other facilities as well - but we had no clear idea of its scope, its targets, possible successes, not of the value of the information they might be collecting.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This paragraph is followed by a large redacted area to this day. And then continues&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;By the early 70’s, evidence had accrued confirming the Soviet intercept effort, and it was shown to be large and efficient. [REDACTED] characterised their intercept effort from their Washington Embassy as the single most valuable covert SIGINT activity in their arsenal. The vulnerable communications obviously extended beyond those of our traditional military and diplomatic customers. Privacy for individual citizens could be violated; technological information communicated by Defense contractors could be compromised, and information useful in economic warfare could be obtained. The threat became public and explicit in the waning days of the Ford Administration with Vice-President Rockefeller announcing in a press conference that “If you don’t want it known, don’t use the phone”. Later on, in a press conference, President Carter acknowledged the existence of the problems, characterized the Soviets’ efforts as passive, noted that all “his” communications were secured and did not appear too upset. Senator Moynihan, however, expressed outrage, wanted to jam the Russians, expel them, or something because of their outrageous invasion of US citizens’ privacy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The reason why the president probably wasn’t that outraged compared to the Senator is probably because he knew the US embassies were doing the same …&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;By this time, we had bitten the bullet, deciding to seek a generic COMSEC solution. This was a decision of enormous consequence for us. The notion of injecting Communications Security into the commercial world in a big way was unprecedented, with serious policy, political, and technical implications for all involved. Principal players became ourselves, the telephone companies, the White House, DCA, the now defunct Office of Telecommunications Policy in OMB, FCC and, ultimately many users of the commercial telephone system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The project was (and is) called HAMPER. At the outset, it had three main thrusts: a greatly expanded program to move “sensitive” circuits to cable in Washington, NYC and San Francisco where major Intercept activities were now known to exist; a program to bulk encrypt some of the tower-to-tower microwave links in their entirety, re-inforced by &lt;strong&gt;end-to-end encryption&lt;/strong&gt; for some particularly critical lines; and the definition of “Protected Communications Zones” to circumscribe those areas - e.g., Washington and its environs - from which microwave interception would be relatively safe and easy. It took several years of concerted effort simply to sort out how communications were routed through the enormously complex telephone system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;With that deployment, cryptography became increasingly prominent in the private sector. Raising some concerns for NSA.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The doctrinal problems were large and intractable because they involved the provision of cryptography in unclassified environments where many of our traditional physical security measures were thought to be inapplicable. How would the crypto-equipments be protected? How to protect the keys? How do you effect key distribution with no secure delivery infrastructure such as we enjoy in the Government COMSEC world? &lt;strong&gt;Problems of this kind let to campaign to use the DES - the only unclassified Government-approved crypto system available&lt;/strong&gt;, thus solving the physical security problem insofar as the crypto-equipment itself was concerned. The root difficulty with this proposal from the security analysts’ viewpoint lay in the fact that the DES algorithm was originally designed and endorsed exclusively for the protection of unclassified data, fundamentally to insure privacy, and without a SIGINT adversary with the power of the Soviet Union having been postulated as a likely attacker. Accordingly, &lt;strong&gt;the system was not designed to meet our high grade standards and were not interested in educating the world at large in the best we can do.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is really interesting. It’s another example of intelligence agencies struggling to reconcile their Information Assurance and SIGINT sides.  They thus admit not protecting citizens and US companies at risk of Soviet spying with the only goal of being still able to spy more on the Soviet.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nonetheless, the system is very strong; has stood up to our continuing analysis, and we still see no solution to it short of a brute force exhaustion of all its 2^56 variables. It is good enough, in fact, to have caused our Director to endorse it not only for its original computer privacy purposes, but for selected classified traffic as well. &lt;strong&gt;Cynics, however, still ask “Are we breaking it?” The answer is no. But could we? The answer is “I don’t know; if I did I wouldn’t tell you” And there’s a good reason for this diffidence. A “No” answer sets an upper limit on our analytic power. A “Yes” answer, a lower limit. Both of those limits are important secrets because of the insights the information would provide to opponents on the security of their own systems.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;NSA won’t reveal if they can break something. We all knew that this was happening but interesting to read an internal document confirming that practice.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;the Hamper program faltered because of uncertainties on who was charged with, responsible for, authorized to, or capable of moving forward. Big money was involved and we didn’t know who should budget for it. Should the common carriers pay for it themselves, or its customers? Or the government? It is, after all, &lt;strong&gt;a security service that most may not want or perceive a need for.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;By and large, most people in both the COMSEC and SIGINT organizations in NSA believe that we can accomplish our missions more effectively in considerable secrecy because it helps us to conceal our strengths and weaknesses and to achieve technological surprise. DoC [Department of Commerce], on the other hand, is in business, in part, to encourage private enterprise, to maximize commercial markets at home and abroad, and to exploit the products of our own Industry for use in Government rather than having the Government compete with Industry and this does not exclude cryptography.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;academic-freedom-vs-national-security&quot;&gt;Academic Freedom vs National Security&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;In any event, production and marketing of equipment by U.S. commercial vendors is not our biggest problem with public cryptography because there are various Government controls on such equipment - particularly, export controls - and Industry itself is usually disinterested in publishing the cryptanalytic aspects of their research in any detail. The central issue that continues to fester is encapsulated in the phrase: “Academic Freedom versus National Security”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Our Director has made a number of overtures to various academic forums and individuals in an effort to de-fuse this issue, but has stuck to his guns with the statement that unrestrained academic research and publication of results can adversely affect National Security. While a few academicians have been sympathetic, the more usual reaction - at least that reaching the press - has been negative.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;The principal reason that there is an NSA consensus that unrestrained academic work has the potential for harm to our mission is because, if first-case U.S. mathematicians, computer scientists, and engineers begin to probe deeply into cryptology, and especially into cryptanalytics, they are likely to educate U.S. SIGINT target countries who may react with improved COMSEC. Less likely, but possible, is their potential for discovering and publishing analytic techniques that might put some U.S. crypto systems in jeopardy.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The academicians’ arguments focus on absolute freedom to research and publish why they please, a rejection of any stifling of intellectual pursuit, and concerns for the chilling effect of any requests for restraint. Their views are bolstered by the real difficulty of differentiating various kinds of mathematical research from “crypto-mathematics” - notably in the burgeoning mathematical field of Computational Complexity, often seeking solutions to difficult computational problems not unlike those posed by good cryptosystems.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;As a practical matter, Government “leverage,” if any, is rather limited. We have made some half-heated attempt to draw an analogy between our concerns for cryptology with those for private research and development in the nuclear weapons field which led to the Atomic Energy Act that does - at least in theory - constrain open work in that field. But there is no comparable public perception of clear and present danger in the case of cryptology and, despite the “law,” academicians have sanctioned research revelatory of atomic secrets including publications on how to build an atomic bomb.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That’s where it gets interesting.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Another wedge, which as yet has not been driven with an appreciable force, is the fact that - overwhelmingly - the money underwriting serious unclassified academic research in cryptography comes from the Government itself. Among them are the National Science Foundation (NSF), the Office of Naval Research (ONR) and the Defense Advanced Research Projects Agency (DARPA). NSA supplies a little itself. &lt;strong&gt;The wedge is blunted because Government officials administering grants from most of these institutions have been drawn largely from the academic community who believe strongly in the value of research performed outside Government, and are sympathetic to concerns about abridgement of Academic Freedom.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In following paragraphs, the author explains that NSA has tried to make more bridges with academia and convince them to be “reasonable”.&lt;/p&gt;

&lt;h2 id=&quot;burn-after-reading&quot;&gt;Burn after reading&lt;/h2&gt;

&lt;p&gt;NSA masters pyrotechnic techniques to burn crypto equipment when it is at risk of compromise. After previous failures of keeping crypto-equipment safe from foreign reverse-engineering, they got a big success during the 1979 Iranian revolution where they burned all of the US equipment that was at risk of being compromised.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The most successful use of pyrotechnics (thermate slabs, thermite grenades, and sodium nitrate barrels) in Tehran occurred at the major Army Communications Center there. It had a number of crypto-equipments, but also served as a depot for pyrotechnic materials for the whole area. They piled all of their classified crypto material in a shed; covered them with their pyrotechnical material (some 300 devices), lit off the whole enchilada, and took off. The result was probably the largest single conflagration during the entire revolution. Observers reported seeing flames shooting hundreds of feet into the air from posts several miles away. The building was, of course, consumed and we assume only a slag pile remains. […]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There are many more topics covered that I have decided to leave out of this summary. If this sounded interesting, you might want to take a look in the COMSEC guide for yourself!&lt;/p&gt;
</description>
        <pubDate>Fri, 18 Dec 2015 18:10:00 +0100</pubDate>
        <link>https://www.fredericjacobs.com/blog/2015/12/18/COMSEC/</link>
        <guid isPermaLink="true">https://www.fredericjacobs.com/blog/2015/12/18/COMSEC/</guid>
        
        
      </item>
    
      <item>
        <title>New Home</title>
        <description>&lt;p&gt;It’s easy to be lazy these days and give up on the decentralized property of the Internet. You can find pretty much everything that requires more than a minute to set up “as a service”. I hadn’t self-hosted my blog for years. What prompted me to go back to self-hosting from Medium?&lt;/p&gt;

&lt;p&gt;Tracking of readers was a concern but didn’t bothered me enough to make the effort of self-hosting. I was increasingly frustrated about not having control over the layout of my posts, not being able to embed code without having to embed a GitHub Gist. And since Medium isn’t monetized yet, I had some uncertainties about the future of the platform.&lt;/p&gt;

&lt;p&gt;Welcome to this new home.&lt;/p&gt;

&lt;p&gt;The pleasure of self-hosting my blog also comes with my renewed love for RSS. You can &lt;a href=&quot;https://www.fredericjacobs.com/blog/feed.xml&quot;&gt;subscribe&lt;/a&gt; to get all the blog posts, without the noise of having to &lt;a href=&quot;https://twitter.com/FredericJacobs&quot;&gt;follow me on Twitter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Note: Previous &lt;a href=&quot;https://medium.com/@FredericJacobs&quot;&gt;blog posts&lt;/a&gt; will stay on Medium.&lt;/p&gt;
</description>
        <pubDate>Sun, 22 Nov 2015 15:33:00 +0100</pubDate>
        <link>https://www.fredericjacobs.com/blog/2015/11/22/new-home/</link>
        <guid isPermaLink="true">https://www.fredericjacobs.com/blog/2015/11/22/new-home/</guid>
        
        
      </item>
    
  </channel>
</rss>
